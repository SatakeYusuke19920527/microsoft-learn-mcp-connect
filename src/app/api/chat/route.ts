/* eslint-disable @typescript-eslint/no-explicit-any */
import { NextRequest, NextResponse } from 'next/server';

// å¿…è¦ãªç’°å¢ƒå¤‰æ•°ã¯ .env.local ãªã©ã§ã‚»ãƒƒãƒˆã—ã¦ãã ã•ã„
const endpoint = process.env.AZURE_OPENAI_ENDPOINT;
const apiKey = process.env.AZURE_API_KEY;
const deployment = process.env.AZURE_OPENAI_DEPLOYMENT;
const apiVersion = '2024-02-15-preview';

export async function POST(req: NextRequest) {
  try {
    const { message } = await req.json();

    console.log('ğŸš€ ~ POST ~ message:', message);
    // Azure OpenAI ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    const url = `${endpoint}/openai/deployments/${deployment}/chat/completions?api-version=${apiVersion}`;

    const aoaiRes = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': apiKey!,
      },
      body: JSON.stringify({
        messages: [
          { role: 'system', content: 'You are a helpful assistant.' },
          { role: 'user', content: message },
        ],
        temperature: 0.7,
        max_tokens: 1000,
      }),
    });

    if (!aoaiRes.ok) {
      const error = await aoaiRes.text();
      return NextResponse.json({ error }, { status: 500 });
    }

    const data = await aoaiRes.json();
    const reply =
      data.choices?.[0]?.message?.content ?? 'AIå¿œç­”å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚';

    return NextResponse.json({ reply });
  } catch (err: any) {
    return NextResponse.json({ error: err.message }, { status: 500 });
  }
}
